{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphFusion\n",
    "\n",
    "> Adapted from SCM/models/graphFusion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.graph_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2966024/3634340846.py:9: DeprecationWarning: Please use `coo_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.coo` namespace is deprecated.\n",
      "  from scipy.sparse.coo import coo_matrix\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import copy\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from typing import Iterable\n",
    "from scipy.sparse.coo import coo_matrix\n",
    "from scipy.sparse import diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def inverse_schulz(X, iteration=5, alpha=0.002):\n",
    "    \"\"\"\n",
    "    Computes an approximation of the matrix inversion using Newton-Schulz\n",
    "    iterations\n",
    "    Source NASA: https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19920002505.pdf\n",
    "    \"\"\"\n",
    "    assert len(X.shape) >= 2, \"Can't compute inverse on non-matrix\"\n",
    "    assert X.shape[-1] == X.shape[-2], \"Must be batches of square matrices\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        device = X.device\n",
    "        eye = torch.eye(X.shape[-1], device=device)\n",
    "        # alpha should be sufficiently small to have convergence\n",
    "        inverse = alpha * torch.transpose(X, dim0=-2, dim1=-1)\n",
    "\n",
    "    for _ in range(iteration):\n",
    "        inverse = inverse @ (2 * eye - X @ inverse)\n",
    "\n",
    "    return inverse\n",
    "\n",
    "class Fuse(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    ----------\n",
    "    Parameters:\n",
    "    - grid_size : tuple of ints\n",
    "    A patched feature map shape to build with.\n",
    "    e.g. [W1, ..., WN] where ï¼š\n",
    "    Wi - patch number of the axis i\n",
    "\n",
    "    - num_connect : int\n",
    "    the number of neighbor units to fuse against.\n",
    "\n",
    "    - dilation : int\n",
    "    the step size for fusion.\n",
    "\n",
    "    - adjMat: coo_matrix\n",
    "    sparse coordinate matrix for adjacent positions relationship.\n",
    "    Matrix is available automatically after the model initialization.\n",
    "    Save and assign a matrix if the attention shape not change for reducing space cost.\n",
    "\n",
    "    - idMat: coo_matrix\n",
    "    sparse coordinate matrix for in-degree relationship.\n",
    "    Matrix is available automatically after the model initialization.\n",
    "    Save and assign a matrix if the attention shape not change for reducing space cost.\n",
    "\n",
    "    - init_cfg (dict, optional): Initialization config dict. Default to None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 grid_size: Iterable[int],\n",
    "                 iteration: int,\n",
    "                 num_connect: int = 4,\n",
    "                 dilation: int = 1,\n",
    "                 adjMat: coo_matrix = None,\n",
    "                 idMat: coo_matrix = None,\n",
    "                 lapMat: coo_matrix = None,\n",
    "                 loss_rate: float = 1, \n",
    "                 init_cfg: dict = None, ):\n",
    "        super(Fuse, self).__init__()\n",
    "\n",
    "        self._grid_size = grid_size\n",
    "        self.num_patch = np.prod(self.grid_size)\n",
    "        self.dimension = len(grid_size)\n",
    "        self.iteration = iteration\n",
    "\n",
    "        self._loss_rate = nn.Parameter(torch.ones([1])*loss_rate)\n",
    "\n",
    "        if num_connect is None:\n",
    "            self._num_connect = self.dimension * 2\n",
    "        elif num_connect < 0:\n",
    "            raise ValueError(\n",
    "                f'Expect connections per unit is positive, but got {num_connect} instead.'\n",
    "            )\n",
    "        else:\n",
    "            self._num_connect = num_connect\n",
    "\n",
    "        self._dilation = dilation\n",
    "        self._adjMat = adjMat\n",
    "        self._idMat = idMat\n",
    "        self._lap = lapMat\n",
    "        \n",
    "        self._lap = self.getLap()\n",
    "        self.init_weights()\n",
    "\n",
    "    def getAdj(self) -> coo_matrix:\n",
    "        if self._adjMat is not None:\n",
    "            return self._adjMat\n",
    "        # patch idx array\n",
    "        idx_row = []\n",
    "        idx_col = []\n",
    " \n",
    "        for idx_r in range(self.num_patch):\n",
    "            idxes = self.getDimIdx(idx_r)\n",
    "            id_c = [[idx - self._dilation, idx + self._dilation]\n",
    "                    for idx in idxes]\n",
    "            id_c = self.selectValidIdx(self.connect(idxes, id_c))\n",
    "            idp_c = [self.getPatchIdx(i) for i in id_c]\n",
    "\n",
    "            for idx_c in idp_c:\n",
    "                idx_row.append(idx_r)\n",
    "                idx_col.append(idx_c)\n",
    "\n",
    "        self._adjMat = coo_matrix((np.full(len(idx_row), 1, dtype=int), (idx_row, idx_col)), shape=(\n",
    "            self.num_patch, self.num_patch), dtype=int)\n",
    "\n",
    "        return self._adjMat\n",
    "\n",
    "    def getIdMat(self):\n",
    "        '''\n",
    "        Get in-degree matrix. Row is the in-direction.\n",
    "        '''\n",
    "        if self._idMat is not None:\n",
    "            return self._idMat\n",
    "        self._adjMat = self.getAdj()\n",
    "        self._idMat = diags(self._adjMat.sum(axis=0).A1)\n",
    "\n",
    "        return self._idMat\n",
    "\n",
    "    def getLap(self):\n",
    "        if self.laplacian is not None:\n",
    "            return self.laplacian\n",
    "        if self.adjMat is None:\n",
    "            self.adjMat = self.getAdj()\n",
    "        if self.idMat is None:\n",
    "            self.idMat = self.getIdMat()\n",
    "\n",
    "        lap = self.idMat - self.adjMat\n",
    "        return lap\n",
    "\n",
    "    def getPatchIdx(self, idxes):\n",
    "        '''\n",
    "        Get patch index by dimension indexes, e.g. idx_patch_D_W_H (2, 10, 9) = 2*s1*s2 + 10*s2 + 9\n",
    "        where s0, s1, s2 is the maximum number of patches along axies.\n",
    "\n",
    "        Without access and output safety check\n",
    "        '''\n",
    "        idx_axis = [idxes[i]*np.prod(self._grid_size[1+i:])\n",
    "                    for i in range(self.dimension)]\n",
    "        return np.sum(idx_axis, dtype=int)\n",
    "\n",
    "    def getDimIdx(self, idx):\n",
    "        '''\n",
    "        Get dimension index by patch idx, e.g. idx_dim_D_W_H (10) = 10/(s1*s2), left/s2, left'\n",
    "        where s0, s1, s2 is the maximum number of patches along axies.\n",
    "\n",
    "        Without access and output safety check\n",
    "        '''\n",
    "        left = idx\n",
    "        idxes = []\n",
    "        for i in range(self.dimension):\n",
    "            prod_ = np.prod(self._grid_size[1+i:], dtype=int)\n",
    "            idx_ = left//prod_\n",
    "            left -= idx_*prod_\n",
    "            idxes.append(idx_)\n",
    "        return idxes\n",
    "\n",
    "    def connect(self, idxes, idxes_ref):\n",
    "        '''\n",
    "        Connect neighbors based on num_connect within dilation range.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        idxes: the original source indexes. e.g. [idx0, ..., idxn-1]\n",
    "        idxes_ref: indexes after dilation. e.g. [(idx0 - self.dilation, idx0 + self.dilation) ...] from dim 0 to dim n-1.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A list of coordinates of range to fuse against.\n",
    "\n",
    "        '''\n",
    "        res = []\n",
    "\n",
    "        # direction 1: extend range along each axis\n",
    "        if self._num_connect == self.dimension*2:\n",
    "            for i, ref in enumerate(idxes_ref):\n",
    "\n",
    "                idxes_1 = copy.deepcopy(idxes)\n",
    "                idxes_1[i] = ref[0]\n",
    "                idxes_2 = copy.deepcopy(idxes)\n",
    "                idxes_2[i] = ref[1]\n",
    "\n",
    "                res.append(idxes_1)\n",
    "                res.append(idxes_2)\n",
    "\n",
    "        # direction 2: combine all conners\n",
    "        elif self._num_connect == self.dimension*2 + np.power(2, self.dimension):\n",
    "            idxes = list(itertools.product(*idxes_ref))\n",
    "            res = idxes\n",
    "\n",
    "        # direction 3: full-range np.power([1+self.dilation*2, 2*self.dilation-1], np.repeat(self.dimension, 2))\n",
    "        elif self._num_connect == np.power(1+self._dilation*2, self.dimension) - np.power(self._dilation*2-1, self.dimension):\n",
    "            res = set()\n",
    "            for i, ref in enumerate(idxes_ref):\n",
    "                idxes_ = copy.deepcopy(idxes_ref)\n",
    "                del idxes_[i]\n",
    "                pf = itertools.product(\n",
    "                    *[list(range(r[0], r[1]+1)) for r in idxes_])\n",
    "                idxes = []\n",
    "                for pf_ in pf:\n",
    "                    pf_1 = list(pf_)\n",
    "                    pf_2 = list(pf_)\n",
    "                    pf_1.insert(i, ref[0])\n",
    "                    pf_2.insert(i, ref[1])\n",
    "                    idxes.append(pf_1)\n",
    "                    idxes.append(pf_2)\n",
    "                res.update(idxes)\n",
    "            res = list(idxes)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f'num_connect {self._num_connect} is not defined in your grid shape settings {self.grid_size}, which is a {len(self.grid_size)}D space.')\n",
    "        return res\n",
    "\n",
    "    def selectValidIdx(self, idxes):\n",
    "        res = list(zip(*idxes))\n",
    "        sel = np.full(len(idxes), True, dtype=bool)\n",
    "        for i, idx in enumerate(res):\n",
    "            a = np.array(idx)\n",
    "            sel = sel & (a >= 0) & (a < self._grid_size[i])\n",
    "\n",
    "        return np.array(idxes)[sel]\n",
    "\n",
    "    @property\n",
    "    def num_connect(self):\n",
    "        return self._num_connect\n",
    "\n",
    "    @num_connect.setter\n",
    "    def num_connect(self, val):\n",
    "        self._num_connect = val\n",
    "\n",
    "    @property\n",
    "    def dilation(self):\n",
    "        return self._dilation\n",
    "\n",
    "    @dilation.setter\n",
    "    def dilation(self, val):\n",
    "        self._dilation = val\n",
    "\n",
    "    @property\n",
    "    def grid_size(self):\n",
    "        return self._grid_size\n",
    "\n",
    "    @property\n",
    "    def adjMat(self):\n",
    "        return self._adjMat\n",
    "\n",
    "    @adjMat.setter\n",
    "    def adjMat(self, val):\n",
    "        self._adjMat = val\n",
    "\n",
    "    @property\n",
    "    def idMat(self):\n",
    "        return self._idMat\n",
    "\n",
    "    @idMat.setter\n",
    "    def idMat(self, val):\n",
    "        self._idMat = val\n",
    "\n",
    "    @property\n",
    "    def laplacian(self):\n",
    "        return self._lap\n",
    "\n",
    "    @laplacian.setter\n",
    "    def laplacian(self, val):\n",
    "        self._lap = val\n",
    "\n",
    "    @property\n",
    "    def loss_rate(self):\n",
    "        return self._loss_rate\n",
    "\n",
    "    @loss_rate.setter\n",
    "    def loss_rate(self, val):\n",
    "        self._loss_rate = nn.Parameter(torch.empty([1])*val)\n",
    "\n",
    "    def forward(self, sim):\n",
    "        r\"\"\"Allows the model to generate the fusion-based attention matrix.\n",
    "        Fuse one time -> one iteration only.\n",
    "    Args:\n",
    "        sim: patch pair wise similarity matrix.\n",
    "\n",
    "        Shapes for inputs:\n",
    "        - sim: :math:`(B, N, N)`, where B is the batch size, N is the target `spatial` sequence length.\n",
    "        Shapes for outputs:\n",
    "        - fAttn_output: :math:`(B, N, N)` where B is the batch size, N is the target `spatial` sequence length.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> d\n",
    "    \"\"\"\n",
    "        if len(sim.shape) != 3:\n",
    "            raise ValueError(\n",
    "                f'Expect the patch pair-wise similarity matrix\\'s shape to be [B, N, N], but got {sim.shape} instead.'\n",
    "            )\n",
    "        assert sim.shape[-1] == self.num_patch and sim.shape[-1] == sim.shape[-2], f'Expect he patch pair-wise similarity matrix to have {self.num_patch} tokens, but got {sim.shape[-1]}.'\n",
    "\n",
    "        # TODO: test the module functionality\n",
    "        with torch.no_grad():\n",
    "            factory_kwargs = {'device': sim.device, 'dtype': sim.dtype}\n",
    "            L = torch.tensor(self.laplacian.todense().A, **factory_kwargs)\n",
    "            # lr = torch.sigmoid(self.loss_rate.to(factory_kwargs['device']))\n",
    "            lr = self.loss_rate.to(factory_kwargs['device'])\n",
    "            \n",
    "        L = torch.mul(L, lr*sim - 1)\n",
    "        L = inverse_schulz(L, iteration=self.iteration)\n",
    "        L = L.transpose(dim0=-2, dim1=-1)\n",
    "\n",
    "        return L\n",
    "\n",
    "    def init_weights(self):\n",
    "\n",
    "        pass\n",
    "        # nn.init.constant_(self.loss_rate, 0)\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = super().__repr__()\n",
    "        s = s[:-2]\n",
    "        s += '\\n  fusion_cfg:('\n",
    "        s += f'\\n    grid_size={self.grid_size}'\n",
    "        s += f'\\n    dilation={self.dilation}'\n",
    "        s += f'\\n    num_connect={self.num_connect}'\n",
    "        s += f'\\n    loss_rate={self.loss_rate}'\n",
    "        s += '\\n))'\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCM",
   "language": "python",
   "name": "scm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

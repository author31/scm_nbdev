{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "\n",
    "> Adapted from SCM/config/default.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp config.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import datetime\n",
    "from loguru import logger\n",
    "from yaml.loader import BaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AttrDict(dict):\n",
    "    \"\"\"\n",
    "    Subclass dict and define getter-setter.\n",
    "    This behaves as both dict and obj.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        return self[key]\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        if key in self.__dict__:\n",
    "            self.__dict__[key] = value\n",
    "        else:\n",
    "            self[key] = value\n",
    "\n",
    "\n",
    "__C = AttrDict()\n",
    "config = __C\n",
    "\n",
    "__C.BASIC = AttrDict()\n",
    "__C.BASIC.TIME = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "__C.BASIC.GPU_ID = [0]\n",
    "__C.BASIC.NUM_WORKERS = 40\n",
    "__C.BASIC.DISP_FREQ = 1\n",
    "__C.BASIC.SEED = 0\n",
    "__C.BASIC.SAVE_DIR = ''\n",
    "__C.BASIC.ROOT_DIR = ''\n",
    "__C.BASIC.BACKUP_CODES = True\n",
    "__C.BASIC.BACKUP_LIST = ['lib', 'tools', 'tools_cls']\n",
    "__C.BASIC.SAVE_ROOT=''\n",
    "\n",
    "\n",
    "# Model options\n",
    "__C.MODEL = AttrDict()\n",
    "__C.MODEL.ARCH = 'vgg16_cam'\n",
    "__C.MODEL.CAM_THR = 0.2\n",
    "__C.MODEL.TOP_K = 1\n",
    "__C.MODEL.LOCALIZER_DIR = ''\n",
    "\n",
    "# Cudnn related setting\n",
    "__C.CUDNN = AttrDict()\n",
    "__C.CUDNN.BENCHMARK = False\n",
    "__C.CUDNN.DETERMINISTIC = True\n",
    "__C.CUDNN.ENABLE = True\n",
    "\n",
    "# Data options\n",
    "__C.DATA = AttrDict()\n",
    "__C.DATA.DATASET = ''\n",
    "__C.DATA.DATADIR = ''\n",
    "__C.DATA.NUM_CLASSES = 20\n",
    "__C.DATA.RESIZE_SIZE = 256\n",
    "__C.DATA.CROP_SIZE = 224\n",
    "__C.DATA.SCALE_SIZE = 196\n",
    "__C.DATA.IMAGE_MEAN = [0.485, 0.456, 0.406]\n",
    "__C.DATA.IMAGE_STD = [0.229, 0.224, 0.225]\n",
    "__C.DATA.SCALE_LENGTH = 15\n",
    "\n",
    "\n",
    "# solver options\n",
    "__C.SOLVER = AttrDict()\n",
    "__C.SOLVER.START_LR = 0.01\n",
    "__C.SOLVER.LR_STEPS = [30]\n",
    "__C.SOLVER.LR_FACTOR = 0.1\n",
    "__C.SOLVER.NUM_EPOCHS = 40\n",
    "__C.SOLVER.WEIGHT_DECAY = 1e-4\n",
    "__C.SOLVER.MUMENTUM = 0.9\n",
    "__C.SOLVER.WARMUP_EPOCHS = 0\n",
    "\n",
    "\n",
    "# Training options.\n",
    "__C.TRAIN = AttrDict()\n",
    "__C.TRAIN.BATCH_SIZE = 16\n",
    "__C.TRAIN.ALPHA = 1.0\n",
    "__C.TRAIN.BETA = 1.0\n",
    "\n",
    "# Testing options.\n",
    "__C.TEST = AttrDict()\n",
    "__C.TEST.BATCH_SIZE = 16\n",
    "__C.TEST.CKPT_DIR = ''\n",
    "__C.TEST.TEN_CROPS = False\n",
    "__C.TEST.SAVE_CAMS = False\n",
    "__C.TEST.SAVE_BOXED_IMAGE = False\n",
    "\n",
    "\n",
    "def merge_dicts(dict_a, dict_b):\n",
    "    from ast import literal_eval\n",
    "    for key, value in dict_a.items():\n",
    "        if key not in dict_b:\n",
    "            raise KeyError('Invalid key in config file: {}'.format(key))\n",
    "        if type(value) is dict:\n",
    "            dict_a[key] = value = AttrDict(value)\n",
    "        if isinstance(value, str):\n",
    "            try:\n",
    "                value = literal_eval(value)\n",
    "            except BaseException:\n",
    "                pass\n",
    "        # The types must match, too.\n",
    "        old_type = type(dict_b[key])\n",
    "        if old_type is not type(value) and value is not None:\n",
    "                raise ValueError(\n",
    "                    'Type mismatch ({} vs. {}) for config key: {}'.format(\n",
    "                        type(dict_b[key]), type(value), key)\n",
    "                )\n",
    "        # Recursively merge dicts.\n",
    "        if isinstance(value, AttrDict):\n",
    "            try:\n",
    "                merge_dicts(dict_a[key], dict_b[key])\n",
    "            except BaseException:\n",
    "                raise Exception('Error under config key: {}'.format(key))\n",
    "        else:\n",
    "            dict_b[key] = value\n",
    "\n",
    "\n",
    "def cfg_from_file(filename):\n",
    "    \"\"\"Load a config file and merge it into the default options.\"\"\"\n",
    "    import yaml\n",
    "    with open(filename, 'r') as fopen:\n",
    "        yaml_config = AttrDict(yaml.load(fopen, BaseLoader))\n",
    "    merge_dicts(yaml_config, __C)\n",
    "\n",
    "\n",
    "def cfg_from_list(args_list):\n",
    "    \"\"\"Set config keys via list (e.g., from command line).\"\"\"\n",
    "    from ast import literal_eval\n",
    "    assert len(args_list) % 2 == 0, 'Specify values or keys for args'\n",
    "    for key, value in zip(args_list[0::2], args_list[1::2]):\n",
    "        key_list = key.split('.')\n",
    "        cfg = __C\n",
    "        for subkey in key_list[:-1]:\n",
    "            assert subkey in cfg, 'Config key {} not found'.format(subkey)\n",
    "            cfg = cfg[subkey]\n",
    "        subkey = key_list[-1]\n",
    "        assert subkey in cfg, 'Config key {} not found'.format(subkey)\n",
    "        try:\n",
    "            # Handle the case when v is a string literal.\n",
    "            val = literal_eval(value)\n",
    "        except BaseException:\n",
    "            val = value\n",
    "        assert isinstance(val, type(cfg[subkey])) or cfg[subkey] is None, \\\n",
    "            'type {} does not match original type {}'.format(\n",
    "                type(val), type(cfg[subkey]))\n",
    "        cfg[subkey] = val\n",
    "\n",
    "\n",
    "def update_config():\n",
    "    # ### configuration\n",
    "    import argparse,sys\n",
    "    parser = argparse.ArgumentParser(description='Classification model training')\n",
    "    parser.add_argument('--config_file', type=str, default=None, required=True,\n",
    "                        help='Optional config file for params')\n",
    "    parser.add_argument('--model', default='deit_base_patch16_224', type=str, metavar='MODEL',\n",
    "                        help='Name of model to train')\n",
    "    parser.add_argument('--input-size', default=224, type=int, help='images input size')\n",
    "\n",
    "    parser.add_argument('--drop', type=float, default=0.0, metavar='PCT',\n",
    "                        help='Dropout rate (default: 0.)')\n",
    "    parser.add_argument('--drop-path', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "\n",
    "    parser.add_argument('--model-ema', action='store_true')\n",
    "    parser.add_argument('--no-model-ema', action='store_false', dest='model_ema')\n",
    "    parser.set_defaults(model_ema=True)\n",
    "    parser.add_argument('--model-ema-decay', type=float, default=0.99996, help='')\n",
    "    parser.add_argument('--model-ema-force-cpu', action='store_true', default=False, help='')\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--opt', default='adamw', type=str, metavar='OPTIMIZER',\n",
    "                        help='Optimizer (default: \"adamw\"')\n",
    "    parser.add_argument('--opt-eps', default=1e-8, type=float, metavar='EPSILON',\n",
    "                        help='Optimizer Epsilon (default: 1e-8)')\n",
    "    parser.add_argument('--opt-betas', default=None, type=float, nargs='+', metavar='BETA',\n",
    "                        help='Optimizer Betas (default: None, use opt default)')\n",
    "    parser.add_argument('--clip-grad', type=float, default=None, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--weight-decay', type=float, default=0.05,\n",
    "                        help='weight decay (default: 0.05)')\n",
    "    # Learning rate schedule parameters\n",
    "    parser.add_argument('--sched', default='cosine', type=str, metavar='SCHEDULER',\n",
    "                        help='LR scheduler (default: \"cosine\"')\n",
    "    parser.add_argument('--lr', type=float, default=5e-4, metavar='LR',\n",
    "                        help='learning rate (default: 5e-4)')\n",
    "    parser.add_argument('--lr-noise', type=float, nargs='+', default=None, metavar='pct, pct',\n",
    "                        help='learning rate noise on/off epoch percentages')\n",
    "    parser.add_argument('--lr-noise-pct', type=float, default=0.67, metavar='PERCENT',\n",
    "                        help='learning rate noise limit percent (default: 0.67)')\n",
    "    parser.add_argument('--lr-noise-std', type=float, default=1.0, metavar='STDDEV',\n",
    "                        help='learning rate noise std-dev (default: 1.0)')\n",
    "    parser.add_argument('--warmup-lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='warmup learning rate (default: 1e-6)')\n",
    "    parser.add_argument('--min-lr', type=float, default=1e-5, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
    "\n",
    "    parser.add_argument('--decay-epochs', type=float, default=30, metavar='N',\n",
    "                        help='epoch interval to decay LR')\n",
    "    parser.add_argument('--warmup-epochs', type=int, default=5, metavar='N',\n",
    "                        help='epochs to warmup LR, if scheduler supports')\n",
    "    parser.add_argument('--cooldown-epochs', type=int, default=10, metavar='N',\n",
    "                        help='epochs to cooldown LR at min_lr, after cyclic schedule ends')\n",
    "    parser.add_argument('--patience-epochs', type=int, default=10, metavar='N',\n",
    "                        help='patience epochs for Plateau LR scheduler (default: 10')\n",
    "    parser.add_argument('--decay-rate', '--dr', type=float, default=0.1, metavar='RATE',\n",
    "                        help='LR decay rate (default: 0.1)')\n",
    "\n",
    "    # Augmentation parameters\n",
    "    parser.add_argument('--color-jitter', type=float, default=0.4, metavar='PCT',\n",
    "                        help='Color jitter factor (default: 0.4)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                        help='Use AutoAugment policy. \"v0\" or \"original\". \" + \\\n",
    "                                 \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.1, help='Label smoothing (default: 0.1)')\n",
    "    parser.add_argument('--train-interpolation', type=str, default='bicubic',\n",
    "                        help='Training interpolation (random, bilinear, bicubic default: \"bicubic\")')\n",
    "\n",
    "    parser.add_argument('--repeated-aug', action='store_true')\n",
    "    parser.add_argument('--no-repeated-aug', action='store_false', dest='repeated_aug')\n",
    "    parser.set_defaults(repeated_aug=True)\n",
    "\n",
    "    # * Random Erase params\n",
    "    parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                        help='Random erase prob (default: 0.25)')\n",
    "    parser.add_argument('--remode', type=str, default='pixel',\n",
    "                        help='Random erase mode (default: \"pixel\")')\n",
    "    parser.add_argument('--recount', type=int, default=1,\n",
    "                        help='Random erase count (default: 1)')\n",
    "    parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                        help='Do not random erase first (clean) augmentation split')\n",
    "\n",
    "    # * Mixup params\n",
    "    parser.add_argument('--mixup', type=float, default=0.8,\n",
    "                        help='mixup alpha, mixup enabled if > 0. (default: 0.8)')\n",
    "    parser.add_argument('--cutmix', type=float, default=1.0,\n",
    "                        help='cutmix alpha, cutmix enabled if > 0. (default: 1.0)')\n",
    "    parser.add_argument('--cutmix-minmax', type=float, nargs='+', default=None,\n",
    "                        help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "    parser.add_argument('--mixup-prob', type=float, default=1.0,\n",
    "                        help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "    parser.add_argument('--mixup-switch-prob', type=float, default=0.5,\n",
    "                        help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "    parser.add_argument('--mixup-mode', type=str, default='batch',\n",
    "                        help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "\n",
    "    # Distillation parameters\n",
    "    parser.add_argument('--teacher-model', default='regnety_160', type=str, metavar='MODEL',\n",
    "                        help='Name of teacher model to train (default: \"regnety_160\"')\n",
    "    parser.add_argument('--teacher-path', type=str, default='')\n",
    "    parser.add_argument('--distillation-type', default='none', choices=['none', 'soft', 'hard'], type=str, help=\"\")\n",
    "    parser.add_argument('--distillation-alpha', default=0.5, type=float, help=\"\")\n",
    "    parser.add_argument('--distillation-tau', default=1.0, type=float, help=\"\")\n",
    "\n",
    "    # * Finetuning params\n",
    "    parser.add_argument('--finetune', default='', help='finetune from checkpoint')\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--data-path', default='/datasets01/imagenet_full_size/061417/', type=str,\n",
    "                        help='dataset path')\n",
    "    parser.add_argument('--data-set', default='IMNET', choices=['CIFAR', 'IMNET', 'INAT', 'INAT19'],\n",
    "                        type=str, help='Image Net dataset path')\n",
    "    parser.add_argument('--inat-category', default='name',\n",
    "                        choices=['kingdom', 'phylum', 'class', 'order', 'supercategory', 'family', 'genus', 'name'],\n",
    "                        type=str, help='semantic granularity')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--opts', help='see config.py for all options',\n",
    "                        default=None, nargs=argparse.REMAINDER)\n",
    "\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "        sys.exit(1)\n",
    "    args = parser.parse_args()\n",
    "    if args.config_file is not None:\n",
    "        cfg_from_file(args.config_file)\n",
    "    if args.opts is not None:\n",
    "        cfg_from_list(args.opts)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCM",
   "language": "python",
   "name": "scm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cams\n",
    "\n",
    "> Adapted from SCM/lib/cams.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from scm_nbdev.utils import mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#TODO refactor draw utils\n",
    "def resize_cam(cam, size=(224, 224)):\n",
    "    cam = cv2.resize(cam, (size[0], size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "    cam = cam - cam.min()\n",
    "    cam = cam / cam.max()\n",
    "    return cam\n",
    "\n",
    "\n",
    "def blend_cam(image, cam):\n",
    "    cam = (cam * 255.).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "    blend = image * 0.5 + heatmap * 0.5\n",
    "\n",
    "    return blend, heatmap\n",
    "\n",
    "\n",
    "def get_bboxes(cam, cam_thr=0.2):\n",
    "    \"\"\"\n",
    "    cam: single image with shape (h, w, 1)\n",
    "    thr_val: float value (0~1)\n",
    "    return estimated bounding box\n",
    "    \"\"\"\n",
    "    cam = (cam * 255.).astype(np.uint8)\n",
    "    map_thr = cam_thr * np.max(cam)\n",
    "\n",
    "    _, thr_gray_heatmap = cv2.threshold(cam,\n",
    "                                        int(map_thr), 255,\n",
    "                                        cv2.THRESH_TOZERO)\n",
    "\n",
    "    try:\n",
    "        _, contours, _ = cv2.findContours(thr_gray_heatmap,\n",
    "                                          cv2.RETR_TREE,\n",
    "                                          cv2.CHAIN_APPROX_SIMPLE)\n",
    "    except:\n",
    "        contours, _ = cv2.findContours(thr_gray_heatmap,\n",
    "                                       cv2.RETR_TREE,\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) != 0:\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        estimated_bbox = [x, y, x + w, y + h]\n",
    "    else:\n",
    "        estimated_bbox = [0, 0, 1, 1]\n",
    "\n",
    "    return estimated_bbox\n",
    "\n",
    "\n",
    "def tensor2image(input, image_mean, image_std):\n",
    "    image_mean = torch.reshape(torch.tensor(image_mean), (1, 3, 1, 1))\n",
    "    image_std = torch.reshape(torch.tensor(image_std), (1, 3, 1, 1))\n",
    "    image = input * image_mean + image_std\n",
    "    image = image.numpy().transpose(0, 2, 3, 1)\n",
    "    image = image[:, :, :, ::-1] * 255\n",
    "    return image\n",
    "\n",
    "\n",
    "def calculate_IOU(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = (xB - xA + 1) * (yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "\n",
    "def draw_bbox(image, iou, gt_box, pred_box, gt_score, is_top1=False):\n",
    "\n",
    "    def draw_bbox(img, box1, box2, color1=(0, 0, 255), color2=(0, 255, 0)):\n",
    "        cv2.rectangle(img, (box1[0], box1[1]), (box1[2], box1[3]), color1, 2)\n",
    "        cv2.rectangle(img, (box2[0], box2[1]), (box2[2], box2[3]), color2, 2)\n",
    "        return img\n",
    "\n",
    "    def mark_target(img, text='target', pos=(25, 25), size=2):\n",
    "        cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), size)\n",
    "        return img\n",
    "\n",
    "    boxed_image = image.copy()\n",
    "\n",
    "    # draw bbox on image\n",
    "    boxed_image = draw_bbox(boxed_image, gt_box, pred_box)\n",
    "\n",
    "    # mark the iou\n",
    "    mark_target(boxed_image, '%.1f' % (iou * 100), (140, 30), 2)\n",
    "    # mark_target(boxed_image, 'IOU%.2f' % (iou), (80, 30), 2)\n",
    "    # # mark the top1\n",
    "    # if is_top1:\n",
    "    #     mark_target(boxed_image, 'Top1', (10, 30))\n",
    "    # mark_target(boxed_image, 'GT_Score%.2f' % (gt_score), (10, 200), 2)\n",
    "\n",
    "    return boxed_image\n",
    "\n",
    "\n",
    "def evaluate_cls_loc(input, cls_label, bbox_label, logits, cams, image_names, cfg, epoch):\n",
    "    \"\"\"\n",
    "    :param input: input tensors of the model\n",
    "    :param cls_label: class label\n",
    "    :param bbox_label: bounding box label\n",
    "    :param logits: classification scores\n",
    "    :param cams: cam of all the classes\n",
    "    :param image_names: names of images\n",
    "    :param cfg: configurations\n",
    "    :param epoch: epoch\n",
    "    :return: evaluate results\n",
    "    \"\"\"\n",
    "    cls_top1 = []\n",
    "    cls_top5 = []\n",
    "    loc_top1 = []\n",
    "    loc_top5 = []\n",
    "    loc_gt_known = []\n",
    "\n",
    "    # label, top1 and top5 results\n",
    "    cls_label = cls_label.tolist()\n",
    "    cls_scores = logits.tolist()\n",
    "    _, top1_idx = logits.topk(1, 1, True, True)\n",
    "    top1_idx = top1_idx.tolist()\n",
    "    _, top5_idx = logits.topk(5, 1, True, True)\n",
    "    top5_idx = top5_idx.tolist()\n",
    "\n",
    "    k = cfg.MODEL.TOP_K\n",
    "    _, topk_idx = logits.topk(k, 1, True, True)\n",
    "    topk_idx = topk_idx.tolist()\n",
    "\n",
    "    batch = cams.shape[0]\n",
    "    image = tensor2image(input.clone().detach().cpu(), cfg.DATA.IMAGE_MEAN, cfg.DATA.IMAGE_STD)\n",
    "\n",
    "    for b in range(batch):\n",
    "\n",
    "        # mean top k\n",
    "        cam_b = cams[b, [cls_label[b]], :, :]\n",
    "        cam_b = torch.mean(cam_b, dim=0, keepdim=True)\n",
    "\n",
    "        cam_b = cam_b.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "        # Resize and Normalize CAM\n",
    "        cam_b = resize_cam(cam_b, size=(cfg.DATA.CROP_SIZE, cfg.DATA.CROP_SIZE))\n",
    "        # Estimate BBOX\n",
    "        estimated_bbox = get_bboxes(cam_b, cam_thr=cfg.MODEL.CAM_THR)\n",
    "\n",
    "        # Calculate IoU\n",
    "        iou = calculate_IOU(bbox_label[b].numpy(), estimated_bbox)\n",
    "\n",
    "        # top1\n",
    "        gt_score = cls_scores[b][top1_idx[b][0]]  # score of gt class\n",
    "        if cls_label[b] in top1_idx[b]:\n",
    "            is_top1 = True\n",
    "            cls_top1.append(1)\n",
    "            if iou>=0.5: loc_top1.append(1)\n",
    "            else: loc_top1.append(0)\n",
    "        else:\n",
    "            is_top1 = False\n",
    "            cls_top1.append(0)\n",
    "            loc_top1.append(0)\n",
    "\n",
    "        # top5\n",
    "        if cls_label[b] in top5_idx[b]:\n",
    "            cls_top5.append(1)\n",
    "            if iou>=0.5: loc_top5.append(1)\n",
    "            else: loc_top5.append(0)\n",
    "        else:\n",
    "            cls_top5.append(0)\n",
    "            loc_top5.append(0)\n",
    "\n",
    "        # gt known\n",
    "        if iou >= 0.5: loc_gt_known.append(1)\n",
    "        else: loc_gt_known.append(0)\n",
    "\n",
    "        # Get blended image\n",
    "        blend, heatmap = blend_cam(image[b], cam_b)\n",
    "        # Get boxed image\n",
    "        boxed_image = draw_bbox(blend, iou, bbox_label[b].numpy(), estimated_bbox, gt_score, is_top1)\n",
    "\n",
    "        # save result\n",
    "        if cfg.TEST.SAVE_BOXED_IMAGE:\n",
    "            image_name = image_names[b]\n",
    "\n",
    "            save_dir = os.path.join(cfg.BASIC.SAVE_DIR, 'boxed_image', str(epoch), image_name.split('/')[0])\n",
    "            save_path = os.path.join(cfg.BASIC.SAVE_DIR, 'boxed_image', str(epoch), image_name)\n",
    "            mkdir(save_dir)\n",
    "            # print(save_path)\n",
    "            cv2.imwrite(save_path, boxed_image)\n",
    "\n",
    "    return cls_top1, cls_top5, loc_top1, loc_top5, loc_gt_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCM",
   "language": "python",
   "name": "scm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

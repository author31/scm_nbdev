{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNetDataset\n",
    "\n",
    "> Adapted from SCM/lib/datasets/imagenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets.imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from pyparsing import original_text_for\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_transforms(cfg):\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((cfg.DATA.RESIZE_SIZE, cfg.DATA.RESIZE_SIZE)),\n",
    "        transforms.RandomCrop((cfg.DATA.CROP_SIZE, cfg.DATA.CROP_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "         transforms.Normalize(list(map(float, cfg.DATA.IMAGE_MEAN)), list(map(float, cfg.DATA.IMAGE_STD)))\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((cfg.DATA.CROP_SIZE, cfg.DATA.CROP_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(list(map(float, cfg.DATA.IMAGE_MEAN)), list(map(float, cfg.DATA.IMAGE_STD)))\n",
    "    ])\n",
    "    orig_transform = transforms.Compose([\n",
    "        transforms.Resize((cfg.DATA.CROP_SIZE, cfg.DATA.CROP_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(list(map(float, cfg.DATA.IMAGE_MEAN)), list(map(float, cfg.DATA.IMAGE_STD)))\n",
    "    ])\n",
    "    test_tencrops_transform = transforms.Compose([\n",
    "        transforms.Resize((cfg.DATA.RESIZE_SIZE, cfg.DATA.RESIZE_SIZE)),\n",
    "        transforms.TenCrop(cfg.DATA.CROP_SIZE),\n",
    "        transforms.Lambda(lambda crops: torch.stack(\n",
    "                [transforms.Normalize(cfg.DATA.IMAGE_MEAN, cfg.DATA.IMAGE_STD)\n",
    "                 (transforms.ToTensor()(crop)) for crop in crops])),\n",
    "    ])\n",
    "    return train_transform, test_transform, test_tencrops_transform, orig_transform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ImageNetDataset(Dataset):\n",
    "    \"\"\" 'ImageNet <https://image-net.org/index.php>'\n",
    "\n",
    "        Args:\n",
    "            root (string): Root directory of dataset where directory \"ImageNet_ILSVRC2012\" exists.\n",
    "            cfg (dict): Hyperparameter configuration.\n",
    "            is_train (bool): If True. create dataset from training set, otherwise creates from test set.\n",
    "        \"\"\"\n",
    "    def __init__(self, root, cfg, is_train, val=False):\n",
    "        self.root = root\n",
    "        self.cfg = cfg\n",
    "        self.is_train = is_train\n",
    "        self.resize_size = cfg.DATA.RESIZE_SIZE\n",
    "        self.crop_size = cfg.DATA.CROP_SIZE\n",
    "\n",
    "        if self.is_train:\n",
    "            datalist = os.path.join(self.root, 'ILSVRC2012_list', 'train.txt')\n",
    "            self.image_dir = os.path.join(self.root, 'train')\n",
    "        else:\n",
    "            datalist = os.path.join(self.root, 'ILSVRC2012_list', 'val_folder_new.txt')\n",
    "            self.image_dir = os.path.join(self.root, 'val')\n",
    "            \n",
    "\n",
    "        names = []\n",
    "        labels = []\n",
    "        bboxes = []\n",
    "        with open(datalist) as f:\n",
    "            for line in f:\n",
    "                info = line.strip().split()\n",
    "                names.append(info[0])\n",
    "                labels.append(int(info[1]))\n",
    "                if self.is_train is False:\n",
    "                    bboxes.append(np.array(list(map(float, info[2:]))).reshape(-1,4))\n",
    "                    # bboxes.append([float(info[i]) for i in range(2, 6)])\n",
    "        self.names = names\n",
    "        self.labels = labels\n",
    "        if self.is_train is False:\n",
    "            self.bboxes = bboxes\n",
    "\n",
    "        self.train_transform, self.onecrop_transform, self.tencrops_transform, self.orig_transform = get_transforms(cfg)\n",
    "        if cfg.TEST.TEN_CROPS:\n",
    "            self.test_transform = self.tencrops_transform\n",
    "        else:\n",
    "            self.test_transform = self.onecrop_transform\n",
    "\n",
    "        self.val = val\n",
    "        \n",
    "        if val:\n",
    "            self.image_dir = self.root\n",
    "            # val2/1/1.jpeg,1\n",
    "            datalist = os.path.join(self.root, 'ILSVRC2012_list', 'val2', 'image_ids.txt')\n",
    "            labelList = os.path.join(self.root, 'ILSVRC2012_list', 'val2','class_labels.txt')\n",
    "            bboxlist = os.path.join(self.root, 'ILSVRC2012_list', 'val2','localization.txt')\n",
    "            mapping_ = os.path.join(self.root, 'ILSVRC2012_list', 'val2','mapping.txt')\n",
    "            \n",
    "            class_labels = {}\n",
    "            boxes = {}\n",
    "            dataList = []\n",
    "            mapping = {}\n",
    "            with open(datalist) as f:\n",
    "                    for line in f.readlines():\n",
    "                        dataList.append(line.strip('\\n'))            \n",
    "            with open(labelList) as f:\n",
    "                for line in f.readlines():\n",
    "                    image_id, class_label = line.strip('\\n').split(',')\n",
    "                    class_labels[image_id] = int(class_label)\n",
    "            with open(bboxlist) as f:\n",
    "                for line in f.readlines():\n",
    "                    image_id, x0s, x1s, y0s, y1s = line.strip('\\n').split(',')\n",
    "                    x0, x1, y0, y1 = int(x0s), int(x1s), int(y0s), int(y1s)\n",
    "                    box = np.array(list(map(float, [x0, x1, y0, y1])))\n",
    "                    if image_id in boxes:\n",
    "                        boxes[image_id].append(box)\n",
    "                    else:\n",
    "                        boxes[image_id] = [box]\n",
    "            with open(mapping_) as f:\n",
    "                for line in f.readlines():\n",
    "                    pre, now =line.strip('\\n').split(',')\n",
    "                    mapping[pre] = now.strip()\n",
    "            \n",
    "            self.val2_class_labels = class_labels\n",
    "            self.val2_boxes = boxes\n",
    "            self.val2_names = dataList\n",
    "            self.val2_mapping = mapping\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.val:\n",
    "            name = self.val2_names[idx] # 'val2/0/0.jpeg'\n",
    "            path = 'val2/'+self.val2_mapping[name] # '0/0.jpeg'\n",
    "       \n",
    "            label = self.val2_class_labels[name]\n",
    "            image = Image.open(os.path.join(self.image_dir, path)).convert('RGB')\n",
    "            \n",
    "        else:        \n",
    "            name = self.names[idx]\n",
    "            label = self.labels[idx]   \n",
    "            image = Image.open(os.path.join(self.image_dir, f\"{name}\")).convert('RGB')\n",
    "            \n",
    "            \n",
    "        image_size = list(image.size)\n",
    "            \n",
    "        if self.is_train:\n",
    "            image = self.train_transform(image)\n",
    "            return image, label\n",
    "\n",
    "        else:\n",
    "            orig = self.orig_transform(image)\n",
    "            image = self.test_transform(image)\n",
    "            \n",
    "            if self.val:\n",
    "                bbox = np.array(self.val2_boxes[name]) # [x0, x1, y0, y1]\n",
    "                [x1, y1, x2, y2] = np.split(bbox, 4, 1)\n",
    "                \n",
    "                # assert(1==0)          \n",
    "            else:\n",
    "                bbox = self.bboxes[idx]\n",
    "                [x1, y1, x2, y2] = np.split(bbox, 4, 1)\n",
    "\n",
    "            resize_size = self.crop_size\n",
    "            crop_size = self.crop_size\n",
    "            shift_size = 0\n",
    "            [image_width, image_height] = image_size\n",
    "            left_bottom_x = np.maximum(x1 / image_width * resize_size - shift_size, 0).astype(int)\n",
    "            left_bottom_y = np.maximum(y1 / image_height * resize_size - shift_size, 0).astype(int)\n",
    "            right_top_x = np.minimum(x2 / image_width * resize_size - shift_size, crop_size - 1).astype(int)\n",
    "            right_top_y = np.minimum(y2 / image_height * resize_size - shift_size, crop_size - 1).astype(int)\n",
    "\n",
    "            gt_bbox = np.concatenate((left_bottom_x, left_bottom_y, right_top_x, right_top_y),axis=1).reshape(-1)\n",
    "            gt_bbox = \" \".join(list(map(str, gt_bbox)))\n",
    "            return image, label, gt_bbox, name, orig\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCM",
   "language": "python",
   "name": "scm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
